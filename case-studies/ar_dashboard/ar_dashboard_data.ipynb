{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This script generates the data used by the stand-alone activity recognition dashboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import json\n",
    "import os\n",
    "\n",
    "import tator\n",
    "import progressbar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Editable section\n",
    "#\n",
    "host = \"https://www.tatorapp.com\"\n",
    "token = \"\"\n",
    "tator_api = tator.get_api(host=host, token=token)\n",
    "\n",
    "# Tator specific constants\n",
    "project = 31\n",
    "state_type = 149\n",
    "multi_type = 55\n",
    "\n",
    "# Define the vessels\n",
    "vessels = {}\n",
    "vessels[\"Arctic Fury (AF)\"] = {\"tag\": \"AF-\"}\n",
    "vessels[\"Lisa Melinda (LM)\"] = {\"tag\": \"LM-\"}\n",
    "vessels[\"Noahs Ark (NA)\"] = {\"tag\": \"NA-\"}\n",
    "\n",
    "vessel_tag_name_map = {}\n",
    "for name in vessels:\n",
    "    vessel_tag_name_map[vessels[name][\"tag\"]] = name\n",
    "\n",
    "# Define the colors used on the timeline\n",
    "color_map = {}\n",
    "color_map[\"Background\"] = \"#6E5CA3\"\n",
    "color_map[\"Fish Activity\"] = \"#915CA3\"\n",
    "color_map[\"Fish Presence\"] = \"#5C6EA3\"\n",
    "color_map[\"Net Activity\"] = \"#6E5CA3\"\n",
    "color_map[\"Offloading\"] = \"#915CA3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Gather all the sections and split them up by vessel\n",
    "#\n",
    "for vessel_name in vessels:\n",
    "    this_vessel = vessels[vessel_name]\n",
    "    this_vessel[\"sections\"] = []\n",
    "\n",
    "sections = tator_api.get_section_list(project=project)\n",
    "for section in sections:\n",
    "    if \"_Trip\" in section.name:\n",
    "        \n",
    "        found_match = False\n",
    "        for tag in vessel_tag_name_map:\n",
    "            vessel_name = vessel_tag_name_map[tag]\n",
    "            if tag in section.name:\n",
    "                vessels[vessel_name][\"sections\"].append(section)\n",
    "                found_match = True\n",
    "                break\n",
    "                \n",
    "        if not found_match:\n",
    "            print(f\"Did not find matching vessel for {section.name}\")\n",
    "            \n",
    "for name in vessels:\n",
    "    print(f\"{name} - {len(vessels[name]['sections'])} trips\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# For each of the vessels, grab the states and medias per section\n",
    "#\n",
    "def filename_to_timestamp(filename):\n",
    "    \"\"\"\n",
    "    Turns a filename into a datetime object. Assumes `filename` is of the format\n",
    "    `<extra>_<%Y%m%d>_<%H%M%S>.<extension>`\n",
    "    \"\"\"\n",
    "    return datetime.datetime.strptime(\n",
    "        \"_\".join(os.path.splitext(filename)[0].split(\"_\")[1:]), \"%Y%m%d_%H%M%S\"\n",
    "    )\n",
    "\n",
    "for vessel_name in vessels:\n",
    "    \n",
    "    fps = None\n",
    "    this_vessel = vessels[vessel_name]\n",
    "    this_vessel[\"multis\"] = []\n",
    "    this_vessel[\"states\"] = []\n",
    "    this_vessel[\"valid_sections\"] = []\n",
    "    this_vessel[\"fps\"] = [] # Assume the FPS is the same for all videos in the multi\n",
    "    this_vessel[\"media_start_time_map\"] = []\n",
    "    this_vessel[\"global_start_time\"] = []\n",
    "    this_vessel[\"global_max_frame\"] = []\n",
    "    \n",
    "    bar = progressbar.ProgressBar()\n",
    "    for section in bar(this_vessel[\"sections\"]):\n",
    "        try:\n",
    "            multis = tator_api.get_media_list(project=project, type=multi_type, section=section.id)\n",
    "\n",
    "            prime_media_ids = [multi.media_files.ids[0] for multi in multis]\n",
    "            states = tator_api.get_state_list(project=project, type=state_type, media_id=prime_media_ids)\n",
    "            \n",
    "            prime_medias = tator_api.get_media_list_by_id(project, {\"ids\": prime_media_ids})\n",
    "            prime_media_map = {}\n",
    "            for media in prime_medias:\n",
    "                prime_media_map[media.id] = media\n",
    "            \n",
    "            global_start_time = datetime.datetime.now()\n",
    "            media_start_time_map = {}\n",
    "            for multi in multis:\n",
    "                start_time = filename_to_timestamp(multi.name)\n",
    "                for media_id in multi.media_files.ids:\n",
    "                    media_start_time_map[media_id] = start_time\n",
    "                \n",
    "                if start_time < global_start_time:\n",
    "                    global_start_time = start_time\n",
    "                \n",
    "            global_max_frame = 0\n",
    "            for multi in multis:\n",
    "                start_time = filename_to_timestamp(multi.name)\n",
    "                max_frame = (start_time - global_start_time).total_seconds() * 15 + prime_media_map[multi.media_files.ids[0]].num_frames\n",
    "                \n",
    "                if max_frame > global_max_frame:\n",
    "                    global_max_frame = max_frame\n",
    "                \n",
    "            this_vessel[\"fps\"].append(15)\n",
    "            this_vessel[\"multis\"].append(multis)\n",
    "            this_vessel[\"states\"].append(states)\n",
    "            this_vessel[\"media_start_time_map\"].append(media_start_time_map)\n",
    "            this_vessel[\"valid_sections\"].append(section)\n",
    "            this_vessel[\"global_start_time\"].append(global_start_time)\n",
    "            this_vessel[\"global_max_frame\"].append(global_max_frame)\n",
    "        except Exception as exc:\n",
    "            print(exc)\n",
    "            print(f\"Error with {section.name}\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Log the activity, start frame, end frame. Convert frames to time.\n",
    "# Stitch all the videos together and apply global frames/time to each event.\n",
    "#\n",
    "vessel_json_data = []\n",
    "\n",
    "for vessel_name in vessels:\n",
    "    this_vessel = vessels[vessel_name]\n",
    "    this_vessel[\"activities\"] = []\n",
    "    num_trips = len(this_vessel[\"valid_sections\"])\n",
    "    \n",
    "    trip_json_data = []\n",
    "    for trip_index in range(num_trips):\n",
    "        \n",
    "        section = this_vessel[\"valid_sections\"][trip_index]\n",
    "        trip_name = section.name\n",
    "        global_start_time = this_vessel[\"global_start_time\"][trip_index]\n",
    "        global_max_frame = this_vessel[\"global_max_frame\"][trip_index]\n",
    "        \n",
    "        activities = {\n",
    "            \"Fish Presence\": {},\n",
    "            \"Fish Activity\": {},\n",
    "            \"Net Activity\": {},\n",
    "            \"Offloading\": {},\n",
    "            \"Background\": {}}\n",
    "        for key in activities:\n",
    "            activities[key] = {\n",
    "                \"start_state_id\": [],\n",
    "                \"end_state_id\": [],\n",
    "                \"global_start_frame\": [],\n",
    "                \"start_frame\": [],\n",
    "                \"start_time\": [],\n",
    "                \"start_multi_media_id\": [],\n",
    "                \"start_multi_media_link\": [],\n",
    "                \"global_end_frame\": [],\n",
    "                \"end_frame\": [],\n",
    "                \"end_time\": [],\n",
    "                \"end_multi_media_id\": [],\n",
    "                \"end_multi_media_link\": []\n",
    "            }\n",
    "        \n",
    "        fps =  this_vessel[\"fps\"][trip_index]\n",
    "        states = this_vessel[\"states\"][trip_index]\n",
    "        media_start_time_map = this_vessel[\"media_start_time_map\"][trip_index] \n",
    "        \n",
    "        multis = this_vessel[\"multis\"][trip_index]\n",
    "        multi_map = {}\n",
    "        for multi in multis:\n",
    "            for media_id in multi.media_files.ids:\n",
    "                multi_map[media_id] = multi.id\n",
    "        \n",
    "        # Collect all the activities and set the times\n",
    "        for state in states:\n",
    "            atype = state.attributes[\"Activity Type\"]\n",
    "            start_frame = state.attributes[\"Start Frame\"]\n",
    "            start_time = datetime.timedelta(seconds=(start_frame / fps)) + media_start_time_map[state.media[0]]\n",
    "            end_frame = state.attributes[\"End Frame\"]\n",
    "            end_time = datetime.timedelta(seconds=(end_frame / fps)) + media_start_time_map[state.media[0]]\n",
    "            multi_id = multi_map[state.media[0]]\n",
    "            global_start_frame = (start_time - global_start_time).total_seconds() * fps\n",
    "            \n",
    "            start_multi_media_link = f\"https://www.tatorapp.com/{project}/annotation/{multi_id}?section={section.id}&frame={start_frame}&selected_entity={state.id}&selected_type=state_{state.meta}&version={state.version}\"\n",
    "            end_multi_media_link = f\"https://www.tatorapp.com/{project}/annotation/{multi_id}?section={section.id}&frame={end_frame}&selected_entity={state.id}&selected_type=state_{state.meta}&version={state.version}\"\n",
    "            \n",
    "            activities[atype][\"start_state_id\"].append(state.id)\n",
    "            activities[atype][\"global_start_frame\"].append(global_start_frame)\n",
    "            activities[atype][\"start_frame\"].append(start_frame)\n",
    "            activities[atype][\"start_time\"].append(start_time)\n",
    "            activities[atype][\"start_multi_media_id\"].append(multi_id)\n",
    "            activities[atype][\"start_multi_media_link\"].append(start_multi_media_link)\n",
    "        \n",
    "            activities[atype][\"end_state_id\"].append(state.id)\n",
    "            activities[atype][\"global_end_frame\"].append(global_start_frame + (end_frame - start_frame))\n",
    "            activities[atype][\"end_frame\"].append(end_frame)\n",
    "            activities[atype][\"end_time\"].append(end_time)\n",
    "            activities[atype][\"end_multi_media_id\"].append(multi_id)\n",
    "            activities[atype][\"end_multi_media_link\"].append(end_multi_media_link)\n",
    "            \n",
    "        # Go through each of the activities and merge gaps if they are within a certain tolerance\n",
    "        tolerance_seconds = 5\n",
    "        final = {}\n",
    "        for atype in activities:\n",
    "\n",
    "            # Sort the lists based on start time\n",
    "            unsorted_list = activities[atype][\"start_time\"]\n",
    "            sort_indexes = sorted(range(len(unsorted_list)),key=unsorted_list.__getitem__)\n",
    "\n",
    "            final[atype] = {}\n",
    "            for key in activities[atype]:\n",
    "                activities[atype][key] = [activities[atype][key][idx] for idx in sort_indexes]\n",
    "                final[atype][key] = []\n",
    "                \n",
    "            # Now, decide which indexes to merge\n",
    "            for idx in range(len(unsorted_list)):\n",
    "                if idx > 0:\n",
    "                    prev_end_time = final[atype][\"end_time\"][-1]\n",
    "                    curr_start_time = activities[atype][\"start_time\"][idx]\n",
    "                    delta_time = (curr_start_time - prev_end_time).total_seconds()\n",
    "                    \n",
    "                    if delta_time <= tolerance_seconds:\n",
    "                        final[atype][\"global_end_frame\"][-1] = activities[atype][\"global_end_frame\"][idx]\n",
    "                        final[atype][\"end_frame\"][-1] = activities[atype][\"end_frame\"][idx]\n",
    "                        final[atype][\"end_time\"][-1] = activities[atype][\"end_time\"][idx]\n",
    "                        final[atype][\"end_multi_media_id\"][-1] = activities[atype][\"end_multi_media_id\"][idx]\n",
    "                        final[atype][\"end_multi_media_link\"][-1] = activities[atype][\"end_multi_media_link\"][idx]\n",
    "                    else:\n",
    "                        for key in activities[atype]:\n",
    "                            final[atype][key].append(activities[atype][key][idx])\n",
    "                else:\n",
    "                    for key in activities[atype]:\n",
    "                        final[atype][key].append(activities[atype][key][idx])\n",
    "            \n",
    "        this_vessel[\"activities\"].append(final)\n",
    "        \n",
    "        # Create the JSON object for the activities\n",
    "        truth_data_json = []\n",
    "        for atype in sorted(final.keys()):\n",
    "            truth_data_json.append({\n",
    "                \"activity\": atype,\n",
    "                \"data\": final[atype],\n",
    "                \"color\": color_map[atype],\n",
    "            })\n",
    "            for start_time in truth_data_json[-1][\"data\"][\"start_time\"]:\n",
    "                truth_data_json[-1][\"data\"][\"start_time\"] = str(start_time)\n",
    "            for end_time in truth_data_json[-1][\"data\"][\"end_time\"]:\n",
    "                truth_data_json[-1][\"data\"][\"end_time\"] = str(end_time)\n",
    "                \n",
    "    \n",
    "        # Create the JSON object for the trip\n",
    "        trip_json_data.append({\n",
    "            \"tripName\": trip_name,\n",
    "            \"truthData\": truth_data_json,\n",
    "            \"globalMaxFrame\": global_max_frame,\n",
    "        })\n",
    "    \n",
    "    vessel_json_data.append({\n",
    "        \"vesselName\": vessel_name,\n",
    "        \"trips\":  trip_json_data\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Create the JS file the dashboard will use directly\n",
    "#\n",
    "with open(\"ar_dashboard_data.js\", \"w\") as file_handle:\n",
    "    file_handle.write(f\"const dataDate = \\\"{datetime.datetime.now()}\\\";\")\n",
    "    file_handle.write(f\"const vesselData = {json.dumps(vessel_json_data)};\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e15202cbffaa11e3d045034fb81da0462d680ae25529d14690beebe3799ab61f"
  },
  "kernelspec": {
   "display_name": "Python 3.8.3 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
